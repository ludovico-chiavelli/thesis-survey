### This script processes the survey_set CSV files, generated by qualtrics-survey-response-analysis/generate_ss_CSVs.py. It generates one big file for easier processing

import pandas as pd
from pathlib import Path
import re

ORIGINAL_SURVEY_GEN_DF = pd.read_csv("/home/nuvolari/GitHub/thesis-survey/final-fullcorpus/final_corpus_cleaned_fsr_survey_marks.csv")

# MODEL_NAME to short name mapping
MODEL_NAME_MAP = {
    "meta-llama/Llama-3.1-8B-Instruct": "llama",
    "google/gemma-2-9b-it": "gemma",
    "mistralai/Mistral-7B-Instruct-v0.3": "mistral"
}

def main():
    survey_set_dir = Path("../survey-set-responses").resolve()
    survey_set_files = list(survey_set_dir.glob("survey_set_*.csv"))
    # Sort files according to number at the end of file stem
    survey_set_files.sort(key=lambda x: int(x.stem.split("_")[-1]))

    # Generate the main DataFrame with rate-type questions
    rateq_main_df = generate_rateq_main_df(survey_set_files)

    # Save the DataFrame to a CSV file
    output_file = "survey_set_main_df.csv"
    rateq_main_df.to_csv(output_file, index=False)

def generate_rateq_main_df(survey_set_files: list) -> pd.DataFrame:
    """
    Generates a main DataFrame with rate-type questions from all survey sets.
    """

    # Columns for the final DataFrame
    columns = [
        "ss_num",
        "response_id",
        "question_id", 
        "prompt_topic",
        "LLM_text",
        "corpus",
        "original_model",
        "human_label",
        "human_label_confidence",
        "true_label"
    ]
        

    # Initialize an empty DataFrame to hold all survey set data
    all_survey_data = pd.DataFrame(columns=columns)

    # Loop through each survey set file
    for file in survey_set_files:
        ss_num = file.stem.split("_")[-1]
        # Read the CSV file
        survey_data = pd.read_csv(file)
        
        # Iterate over file rows, starting from the 3rd row
        # and skipping the first two rows
        # to get the relevant data
        
        for index, row in survey_data.iloc[2:].iterrows():
            
            response_id = row["ResponseId"]

            # Extract the rate question IDs using columns. Search pattern is "Rate" + "EF" or "BA" and a number then terminate.
            search_pattern = re.compile(r"Rate(EF|BA)\d+$")
            rate_question_ids = [col for col in survey_data.columns if search_pattern.search(col)]

            # Find the following for the question ID in the ORIGINAL_SURVEY_GEN_FILEPATH.
            # Get the topic for each question ID
            # Get the LLM text
            # Get the LLM name
            # Mark the corpus
            q_id_metadata_map = {}
            
            for question_id in rate_question_ids:
                q_id_metadata_map[question_id] = {
                    "topic": None,
                    "llm_text": None,
                    "llm_name": None,
                    "corpus": None,
                    "human_label": None,
                    "confidence": None
                }
                # Get the topic for each question ID
                topic = ORIGINAL_SURVEY_GEN_DF.loc[ORIGINAL_SURVEY_GEN_DF["SURVEY_ITEM"] == question_id, "TOPIC"].values[0]
                q_id_metadata_map[question_id]["topic"] = topic

                # Get the LLM text
                llm_text = ORIGINAL_SURVEY_GEN_DF.loc[ORIGINAL_SURVEY_GEN_DF["SURVEY_ITEM"] == question_id, "MODEL_TEXT"].values[0]
                q_id_metadata_map[question_id]["llm_text"] = llm_text

                # Get the LLM name
                model_name = ORIGINAL_SURVEY_GEN_DF.loc[ORIGINAL_SURVEY_GEN_DF["SURVEY_ITEM"] == question_id, "MODEL_NAME"].values[0]
                llm_name = MODEL_NAME_MAP.get(model_name, "unknown")
                q_id_metadata_map[question_id]["llm_name"] = llm_name

                # Mark the corpus by checking question ID
                if "EF" in question_id:
                    corpus = "EFCAMDAT"
                elif "BA" in question_id:
                    corpus = "BAWE"
                else:
                    corpus = "unknown"
                
                q_id_metadata_map[question_id]["corpus"] = corpus

                # Get the human label for the question ID at the matchin index
                raw_answer = row[question_id]

                if raw_answer == "1 - Definitely AI":
                    human_label = "model"
                    confidence = 1
                elif raw_answer == "2 - Likely AI":
                    human_label = "model"
                    confidence = 0.5
                elif raw_answer == "3 - Likely human":
                    human_label = "human"
                    confidence = 0.5
                elif raw_answer == "4 - Definitely human":
                    human_label = "human"
                    confidence = 1
                else:
                    ValueError(f"Unknown answer format: {raw_answer}")
                    human_label = "unknown"
                    confidence = 0
                
                q_id_metadata_map[question_id]["human_label"] = human_label
                q_id_metadata_map[question_id]["confidence"] = confidence

                response_row = {
                    "ss_num": ss_num,
                    "response_id": response_id,
                    "question_id": question_id,
                    "prompt_topic": q_id_metadata_map[question_id]["topic"],
                    "LLM_text": q_id_metadata_map[question_id]["llm_text"],
                    "corpus": q_id_metadata_map[question_id]["corpus"],
                    "original_model": q_id_metadata_map[question_id]["llm_name"],
                    "human_label": q_id_metadata_map[question_id]["human_label"],
                    "human_label_confidence": q_id_metadata_map[question_id]["confidence"],
                    "true_label": "model" # All rate question texts are model
                }

                # Append the response row to the DataFrame
                all_survey_data = pd.concat([all_survey_data, pd.DataFrame([response_row])], ignore_index=True)
        
    return all_survey_data

            
        
        

if __name__ == "__main__":
    main()